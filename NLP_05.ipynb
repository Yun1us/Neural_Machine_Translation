{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f20af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   EN                                  FR\n",
      "0           i m at a loss for words .               j en perds mes mots .\n",
      "1           i m at a loss for words .              les mots me manquent .\n",
      "2           i m at a loss for words .         je ne trouve pas les mots .\n",
      "3  you re in better shape than i am .  tu es en meilleure forme que moi .\n",
      "4                 you are in my way .              tu es sur mon chemin .\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "dataset = pd.read_csv(\"data.csv\") \n",
    "print(dataset.head())\n",
    "en_sentences = dataset[\"EN\"].tolist()\n",
    "fr_sentences = dataset[\"FR\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "913f536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.max_len = 30\n",
    "        self.token_to_ids = {\"<UNK>\": 0}\n",
    "        self.id_to_token = {0: \"<UNK>\"}\n",
    "        self.special_tokens = [\"<pad>\", \"<sos>\", \"<eos>\"]\n",
    "        for token in self.special_tokens:\n",
    "            self.add_token(token)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token not in self.token_to_ids:\n",
    "            id = len(self.token_to_ids)\n",
    "            self.token_to_ids[token] = id\n",
    "            self.id_to_token[id] = token \n",
    "    \n",
    "    def sentence_to_id(self, sentence, maxlen):\n",
    "        attention_id = []\n",
    "        id_list = []\n",
    "        words = [\"<sos>\"] + sentence.split() + [\"<eos>\"]\n",
    "\n",
    "        for word in words:\n",
    "            if word in self.token_to_ids.keys():\n",
    "                id_list.append(self.token_to_ids[word])\n",
    "                attention_id.append(1)\n",
    "            else:\n",
    "                id_list.append(self.token_to_ids[\"<UNK>\"])\n",
    "                attention_id.append(1)\n",
    "\n",
    "        if len(id_list) > maxlen:\n",
    "            id_list = id_list[:maxlen]\n",
    "        while len(id_list) < maxlen:\n",
    "            id_list.append(self.token_to_ids[\"<pad>\"])\n",
    "            attention_id.append(0)\n",
    "        \n",
    "        return id_list, attention_id\n",
    "\n",
    "    def id_to_sentence(self, ids):\n",
    "        words = []\n",
    "        for id in ids:\n",
    "            token = self.id_to_token.get(id,\"<UNK>\")\n",
    "            if token == \"<eos>\":\n",
    "                break\n",
    "            if token in [\"<sos>\", \"<pad>\"]:\n",
    "                continue \n",
    "            words.append(token)\n",
    "        return \" \".join(words)\n",
    "\n",
    "    def build_Vocab(self, sentences):\n",
    "    \n",
    "        for sentence in sentences:\n",
    "            tokens = sentence.lower().split()\n",
    "            for token in tokens:\n",
    "                self.add_token(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8feb701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([12, 30])\n"
     ]
    }
   ],
   "source": [
    "en_vocab = Vocab()\n",
    "fr_vocab = Vocab()\n",
    "\n",
    "en_vocab.build_Vocab(en_sentences)\n",
    "fr_vocab.build_Vocab(fr_sentences)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class EN_FR_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, en_sentences, fr_sentences, en_vocab, fr_vocab):\n",
    "        self.en_sentences = en_sentences\n",
    "        self.fr_sentences = fr_sentences\n",
    "        self.en_vocab = en_vocab\n",
    "        self.fr_vocab = fr_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.en_sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        en_sentences = self.en_sentences[index]\n",
    "        fr_sentences = self.fr_sentences[index]\n",
    "\n",
    "        en_ids, en_attention = self.en_vocab.sentence_to_id(en_sentences, 30)\n",
    "        fr_ids, fr_attention = self.fr_vocab.sentence_to_id(fr_sentences, 30)\n",
    "\n",
    "        return torch.tensor(en_ids), torch.tensor(en_attention, dtype=torch.bool), torch.tensor(fr_ids), torch.tensor(fr_attention, dtype=torch.bool)\n",
    "\n",
    "dataset = EN_FR_Dataset(en_sentences, fr_sentences, en_vocab, fr_vocab)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    en_ids, en_attention, fr_ids, fr_attention = batch\n",
    "    print(en_ids.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, input_size, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "\n",
    "        self.input_embed = nn.Embedding(vocab_size,input_size)   \n",
    "        self.gru = nn.GRU(input_size, hidden_dim, batch_first=True, bidirectional=False)\n",
    "\n",
    "\n",
    "    def forward(self, batch):\n",
    "        embedded_vector = self.input_embed(batch)\n",
    "        encoder_output, last_hidden = self.gru(embedded_vector)\n",
    "        print(encoder_output.shape)\n",
    "        print(last_hidden.shape)\n",
    "\n",
    "        return encoder_output, last_hidden #encoder outputs enthält die gesamte information der hidden states pro wort \n",
    "                                            #last_hidden verwenden wir für die initialisierung des decoders (ist der letzte hidden state vom encoder satz der die ganze info enthält)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff37ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class BahdanauAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, attention_dim, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(encoder_hidden_dim, attention_dim)\n",
    "        self.w2 = nn.Linear(decoder_hidden_dim, attention_dim)\n",
    "        self.v = nn.Linear(attention_dim, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        h = self.w1(encoder_outputs)\n",
    "        s = self.w2(decoder_hidden).unsqueeze(1)\n",
    "\n",
    "        score = self.tanh(h + s)        \n",
    "        score_full = self.v(score) \n",
    "\n",
    "        attention_weights = torch.softmax(score_full, dim=1)\n",
    "        context_vector = torch.sum(attention_weights * encoder_outputs, dim=1)\n",
    "        \n",
    "        return context_vector, attention_weights.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module): \n",
    "    def __init__(self, target_vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(target_vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim + hidden_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "        self.attention = BahdanauAttention(128, encoder_hidden_dim=hidden_dim, decoder_hidden_dim=hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim + hidden_dim, target_vocab_size)\n",
    "\n",
    "    def forward(self, input_token, last_hidden, encoder_outputs):\n",
    "        token_embed = self.embedding(input_token)\n",
    "        print(last_hidden.shape)\n",
    "        print(input_token.shape)\n",
    "        context_vec, _  = self.attention(decoder_hidden[0], encoder_outputs) \n",
    "\n",
    "        concat_vec = torch.cat([token_embed,context_vec], dim=1)\n",
    "        gru_input = concat_vec.unsqueeze(1)\n",
    "\n",
    "        decoder_output, decoder_hidden = self.gru(gru_input, last_hidden)\n",
    "        decoder_output = decoder_output.squeeze(1)\n",
    "\n",
    "        dec_concat = torch.cat([decoder_hidden[0],context_vec], dim=1)\n",
    "\n",
    "        logits = self.fc(dec_concat)\n",
    "\n",
    "        return logits, decoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f54b1a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m encoder = \u001b[43mEncoder\u001b[49m(source_vocab_size, embedding_dim, hidden_dim)\n\u001b[32m      2\u001b[39m decoder = Decoder(target_vocab_size, embedding_dim, hidden_dim)\n\u001b[32m      3\u001b[39m attention = BahdanauAttention(attention_dim, hidden_dim, hidden_dim)\n",
      "\u001b[31mNameError\u001b[39m: name 'Encoder' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
