# Neural Machine Translation Demo

A PyTorch-based Englishâ†’French sequenceâ€‘toâ€‘sequence model with Bahdanau attention.

## ğŸ“‹ Overview

* Trains a single-layer GRU encoder/decoder with attention.
* Supports teacher forcing in training and greedy decoding in validation.
* Computes corpus BLEU and tracks loss/perplexity via TensorBoard.
* Visualizes an attention heatmap for the first validation batch.

## âš™ï¸ Requirements

* Python 3.8+
* PyTorch
* scikit-learn
* HuggingFace `datasets` & `evaluate` (or fallback: NLTK)
* Matplotlib

## ğŸš€ Installation

```bash
git clone <repo-url>
cd your-project
pip install -r requirements.txt
```

## â–¶ï¸ Running

```bash
python NLP_05.py            # trains & validates model
tensorboard --logdir runs   # launch TensorBoard dashboard
```

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ data.csv                # parallel ENâ†”FR corpus
â”œâ”€â”€ NLP_05.py               # main training & evaluation script
â”œâ”€â”€ runs/                   # TensorBoard logs
â”œâ”€â”€ README.md               # this file
```

## ğŸ“ˆ Results

* Training loss & perplexity curves in TensorBoard
* Validation loss & BLEU score per epoch
* Example attention heatmap displayed at validation

---

Feel free to tweak hyperparameters at the top of `NLP_05.py` for your experiments.
